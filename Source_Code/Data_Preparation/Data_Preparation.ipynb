{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "# List of functions for loading German Traffic Sign Data Set for (Training and Testing)\n",
    "def IntialiseEnv():\n",
    "    nb_dir = os.path.split(os.getcwd())[0]\n",
    "    if nb_dir not in sys.path:\n",
    "        sys.path.append(nb_dir)\n",
    "    invalid_path='/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "    if invalid_path in sys.path:\n",
    "        sys.path.remove(invalid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from D:\\github\\Traffic_Sign_Recognition_Detection\\Source_Code\\Feature_Extraction\\Segmentation.ipynb\n"
     ]
    }
   ],
   "source": [
    "## Import libraries need to be imported, Dont forget to update requirements.txt!\n",
    "import os\n",
    "import sys\n",
    "IntialiseEnv()\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "import pandas as pd \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from Feature_Extraction.Segmentation import FeatureExtraction\n",
    "from Feature_Extraction.Segmentation import FeatureExtractionWithoutGrayScaleConversion\n",
    "from Feature_Extraction.Segmentation import augment_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get category directory and corresponding data frame\n",
    "def getDirAndDataFrame(_dir):\n",
    "    train_category_dir= os.path.join(training_dataset_dir,_dir)\n",
    "    train_csv_path= getCsvPath(train_category_dir)\n",
    "    train_Data_frame = pd.read_csv(train_csv_path, delimiter=';')\n",
    "    return train_category_dir, train_Data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get csv path\n",
    "def getCsvPath(train_path_dir):\n",
    "     return os.path.join(train_path_dir,list(filter(lambda x: '.csv' in x, os.listdir(train_path_dir)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read image in path\n",
    "def readImage(path):\n",
    "    img= cv2.imread(path)\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img= cv2.resize(img,(80,80))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSampleImg(path):\n",
    "    img=readImage(path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training DataSet Directory\n",
    "training_dataset_dir = '../DataSet/Training_DataSet/Final_Training/Images'\n",
    "\n",
    "def LoadTrainDataSet():\n",
    "    train_image_array=[]\n",
    "    train_labels_array=[]\n",
    "\n",
    "    for _dir in os.listdir(training_dataset_dir):\n",
    "        print(\"Directory: \", _dir)\n",
    "        # Get Directory for train with certain class ID and its associated dataframe\n",
    "        train_category_dir, train_data_frame= getDirAndDataFrame(_dir)\n",
    "        # Get ClassID for entire category\n",
    "        dir_img_label=train_data_frame.iloc[0]['ClassId']\n",
    "\n",
    "        for img_path in glob.glob(os.path.join(train_category_dir, '*.ppm')):\n",
    "\n",
    "            #Load image in category path directory + Extraction of features\n",
    "            img = readImage(img_path)\n",
    "            img_features = np.array(FeatureExtraction(img))[:,:,np.newaxis]\n",
    "            train_image_array.append(img_features)\n",
    "            #Populate associated labels\n",
    "            train_labels_array.append(dir_img_label)\n",
    "            \n",
    "    train_image_array=np.stack(train_image_array, axis=0)\n",
    "    return train_image_array, train_labels_array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTrainDataSetWithAugmentation():\n",
    "    train_image_array=[]\n",
    "    train_labels_array=[]\n",
    "\n",
    "    for _dir in os.listdir(training_dataset_dir):\n",
    "        print(\"Directory: \", _dir)\n",
    "        # Get Directory for train with certain class ID and its associated dataframe\n",
    "        train_category_dir, train_data_frame= getDirAndDataFrame(_dir)\n",
    "        # Get ClassID for entire category\n",
    "        dir_img_label=train_data_frame.iloc[0]['ClassId']\n",
    "\n",
    "        for img_path in glob.glob(os.path.join(train_category_dir, '*.ppm')):\n",
    "\n",
    "            #Load image in category path directory + Extraction of features\n",
    "            img = readImage(img_path)\n",
    "            img_features = np.array(FeatureExtraction(img))[:,:,np.newaxis]\n",
    "            train_image_array.append(img_features)\n",
    "            #Populate associated labels\n",
    "            train_labels_array.append(dir_img_label)\n",
    "            #### for agumentation \n",
    "            random_number_probability=random.uniform(0, 1)\n",
    "            if random_number_probability>=0.5:\n",
    "                agumented_image=augment_image(img,0.7,11,5,2)\n",
    "                img_features_= np.array(FeatureExtraction(agumented_image))[:,:,np.newaxis]\n",
    "                train_labels_array.append(dir_img_label)\n",
    "                train_image_array.append(img_features_)\n",
    "            \n",
    "    train_image_array=np.stack(train_image_array, axis=0)\n",
    "    return train_image_array, train_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTrainDataSetWithAugmentationFeatureExtractionModified():\n",
    "    train_image_array=[]\n",
    "    train_labels_array=[]\n",
    "\n",
    "    for _dir in os.listdir(training_dataset_dir):\n",
    "        print(\"Directory: \", _dir)\n",
    "        # Get Directory for train with certain class ID and its associated dataframe\n",
    "        train_category_dir, train_data_frame= getDirAndDataFrame(_dir)\n",
    "        # Get ClassID for entire category\n",
    "        dir_img_label=train_data_frame.iloc[0]['ClassId']\n",
    "\n",
    "        for img_path in glob.glob(os.path.join(train_category_dir, '*.ppm')):\n",
    "\n",
    "            #Load image in category path directory + Extraction of features\n",
    "            img = readImage(img_path)\n",
    "            img_features = np.float32(FeatureExtractionWithoutGrayScaleConversion(img))\n",
    "            train_image_array.append(img_features)\n",
    "            #Populate associated labels\n",
    "            train_labels_array.append(dir_img_label)\n",
    "            #### for agumentation \n",
    "            random_number_probability=random.uniform(0, 1)\n",
    "            if random_number_probability>=0.5:\n",
    "                agumented_image=augment_image(img,0.7,11,5,2)\n",
    "                img_features_= np.float32(FeatureExtractionWithoutGrayScaleConversion(agumented_image))\n",
    "                train_labels_array.append(dir_img_label)\n",
    "                train_image_array.append(img_features_)\n",
    "            \n",
    "    train_image_array=np.stack(train_image_array, axis=0)\n",
    "    return train_image_array, train_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir='../DataSet/Testing_DataSet/Final_Test/Images/'\n",
    "labels_dir='../DataSet/Testing_DataSet/GT-final_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTestDataSet():\n",
    "    test_image_array=[]\n",
    "    test_image_labels=[]\n",
    "    test_Data_frame = pd.read_csv(labels_dir, delimiter=';')\n",
    "   \n",
    "    for _dir in os.listdir(test_dir):\n",
    "        if _dir=='GT-final_test.test.csv':\n",
    "            continue\n",
    "        print(\"Directory: \", _dir)\n",
    "        list_=test_Data_frame[test_Data_frame['Filename'] == _dir].index.tolist()\n",
    "        dir_img_label=test_Data_frame.iloc[list_[0]]['ClassId']\n",
    "        \n",
    "        img = readImage(test_dir+_dir)\n",
    "        img_features = np.array(FeatureExtraction(img))[:,:,np.newaxis]\n",
    "        test_image_array.append(img_features)\n",
    "        test_image_labels.append(dir_img_label)\n",
    "        \n",
    "        \n",
    "    test_image_array=np.stack(test_image_array, axis=0)\n",
    "    return   test_image_array, test_image_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTestDataSetFeatureExtractionModified():\n",
    "    test_image_array=[]\n",
    "    test_image_labels=[]\n",
    "    test_Data_frame = pd.read_csv(labels_dir, delimiter=';')\n",
    "   \n",
    "    for _dir in os.listdir(test_dir):\n",
    "        if _dir=='GT-final_test.test.csv':\n",
    "            continue\n",
    "        print(\"Directory: \", _dir)\n",
    "        list_=test_Data_frame[test_Data_frame['Filename'] == _dir].index.tolist()\n",
    "        dir_img_label=test_Data_frame.iloc[list_[0]]['ClassId']\n",
    "        \n",
    "        img = readImage(test_dir+_dir)\n",
    "        img_features = np.array(FeatureExtractionWithoutGrayScaleConversion(img))\n",
    "        test_image_array.append(img_features)\n",
    "        test_image_labels.append(dir_img_label)\n",
    "        \n",
    "        \n",
    "    test_image_array=np.stack(test_image_array, axis=0)\n",
    "    return   test_image_array, test_image_labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
