{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MisClassified Images for Croatian on Winning Model\n",
    "### Environment Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntialiseEnv():\n",
    "    nb_dir = os.path.split(os.getcwd())[0]\n",
    "    if nb_dir not in sys.path:\n",
    "        sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\Users\\Rana Mostafa\\Desktop\\Cairo_University\\Research_Projects\\Traffic_Sign_Recognition\\Source_Code\\Pre_Processing\\Pre_Processing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "IntialiseEnv()\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "import pandas as pd \n",
    "import random\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "\n",
    "from Pre_Processing.Pre_Processing import FeatureExtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GPU/ CPU Configuration \n",
    "Tensorflow version 2.0\n",
    "Prompt to user if CPU/ GPU is in use with device name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "/device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Use GPU/CPU Configurations\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters tuning\n",
    "kernel_2 = (3,3)\n",
    "pooling = (2,2)\n",
    "dropout = 0.3\n",
    "num_classes = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,SpatialDropout2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Add,AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D,BatchNormalization,Dropout,MaxPool2D,Flatten,Dense\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay=1E-4\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def model_():\n",
    "    model = None\n",
    "    tf.initializers.Orthogonal(gain=1.0, seed=None)\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(32,(5,5), input_shape=(60,60,1), strides = 1, padding='valid',activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3), activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64,(5,5), strides = 1, padding='valid', activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3), activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256,(5,5), strides = 1, padding='valid', activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_2, activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model=model_()\n",
    "    model.load_weights('../Model/Trained_Models/Croatian_Winning_99_55.h5')\n",
    "    model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read image in path\n",
    "def readImage(path):\n",
    "    img= cv2.imread(path)\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img= cv2.resize(img,(60,60))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get csv path\n",
    "def getCsvPath(train_path_dir):\n",
    "     return os.path.join(train_path_dir,list(filter(lambda x: '.csv' in x, os.listdir(train_path_dir)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get category directory and corresponding data frame\n",
    "def getDirAndDataFrame(datasetDir,_dir):\n",
    "    train_category_dir= os.path.join(datasetDir,_dir)\n",
    "    train_csv_path= getCsvPath(train_category_dir)\n",
    "    train_Data_frame = pd.read_csv(train_csv_path, delimiter=';')\n",
    "    return train_category_dir, train_Data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateMisClassifiedBatchFileCmd():\n",
    "    test_belgium_dataset_dir='../DataSet/Croatian_DataSet/rmastif_Testing/'\n",
    "    f= open(\"misclassified_croatian.cmd\",\"w+\")\n",
    "    for _dir in os.listdir(test_belgium_dataset_dir):\n",
    "            print(\"Directory: \", _dir)\n",
    "            # Get Directory for train with certain class ID and its associated dataframe\n",
    "            test_category_dir, test_data_frame= getDirAndDataFrame(test_belgium_dataset_dir, _dir)\n",
    "            # Get ClassID for entire category\n",
    "            if len(test_data_frame['ClassId']) == 0:\n",
    "                print(\"Skipping Directory \"+ _dir + \" No test images available\")\n",
    "                continue\n",
    "\n",
    "            img_label=test_data_frame.iloc[0]['ClassId']\n",
    "\n",
    "            for img_path in glob.glob(os.path.join(test_category_dir, '*.ppm')):\n",
    "\n",
    "                #Load image in category path directory + Extraction of features\n",
    "                img = readImage(img_path)\n",
    "                img_features = np.array(FeatureExtraction(img))[:,:,np.newaxis]\n",
    "                prediction= model.predict(img_features.reshape(1,60,60,1))\n",
    "                if np.argmax(prediction) != img_label:\n",
    "                    image= img_path.replace(\"\\\\\",r\"/\")\n",
    "                    image=image.replace(r\"/\",r\"\\\\\")\n",
    "\n",
    "                    image_final= re.split(r\"\\\\\", img_path)[1][:-4]\n",
    "                    image_final=image_final+\"_\"+str(np.argmax(prediction))+\"_\"+str(img_label)+\".ppm\"\n",
    "                    f.write(\"copy \"+image+ \" MisClassification_Croatian_Images\\\\\"+image_final +\"\\n\")\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory:  00000\n",
      "Directory:  00001\n",
      "Directory:  00002\n",
      "Directory:  00003\n",
      "Directory:  00004\n",
      "Directory:  00005\n",
      "Directory:  00006\n",
      "Directory:  00007\n",
      "Directory:  00008\n",
      "Directory:  00009\n",
      "Directory:  00010\n",
      "Directory:  00011\n",
      "Directory:  00012\n",
      "Directory:  00013\n",
      "Directory:  00014\n",
      "Directory:  00015\n",
      "Directory:  00016\n",
      "Directory:  00017\n",
      "Directory:  00018\n",
      "Directory:  00019\n",
      "Directory:  00020\n",
      "Directory:  00021\n",
      "Directory:  00022\n",
      "Directory:  00023\n",
      "Directory:  00024\n",
      "Directory:  00025\n",
      "Directory:  00026\n",
      "Directory:  00027\n",
      "Directory:  00028\n",
      "Directory:  00029\n",
      "Directory:  00030\n"
     ]
    }
   ],
   "source": [
    "CreateMisClassifiedBatchFileCmd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
