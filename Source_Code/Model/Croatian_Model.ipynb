{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqZ4Clw_THwq"
   },
   "source": [
    "# Traffic Sign Recognition Model\n",
    "## Environment Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gr3zzhaiTHws"
   },
   "outputs": [],
   "source": [
    "def IntialiseEnv():\n",
    "    nb_dir = os.path.split(os.getcwd())[0]\n",
    "    if nb_dir not in sys.path:\n",
    "        sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "e3cgtbNlTHw3",
    "outputId": "adb81238-5f27-4e59-ca85-93d80bddcf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "'My Drive'\n",
      "Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/\")\n",
    "!ls\n",
    "import os\n",
    "os.chdir(\"My Drive/[ Masters ] - Deep Learning Proj/Model\")\n",
    "!pip install import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWBuWjUATHxD"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "IntialiseEnv()\n",
    "import import_ipynb\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from Data_Preparation.Data_Preparation_Croatian import LoadCroatianTrainDataSet\n",
    "# from Data_Preparation.Data_Preparation_Croatian import LoadCroatianTestDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcaReyw1THxK"
   },
   "source": [
    "## Use GPU/ CPU Configuration \n",
    "Tensorflow version 2.0\n",
    "Prompt to user if CPU/ GPU is in use with device name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Oy0YZtldTHxL",
    "outputId": "14e7f620-3270-451a-af5b-431722fa0924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "/device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Use GPU/CPU Configurations\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XnCNhIOTHxU"
   },
   "outputs": [],
   "source": [
    "def ReadTrainDataSet():\n",
    "    print(\"Reading Train Pre-processed DataSet\")\n",
    "    processedTrainDataSet = '../DataSet/Processed_DataSet/CroatianTrainDataSet.pkl'\n",
    "    isProcessedTrainDataSetExits= os.path.exists(processedTrainDataSet)\n",
    "    train_image_array, train_image_labels = None, None\n",
    "    train_image_array_final=[]\n",
    "    train_image_labels_final=[]\n",
    "    \n",
    "    if isProcessedTrainDataSetExits:\n",
    "        print(\"Loading Processed Train DataSet from Processed_DataSet/CroatianTrainDataSet.pkl\")\n",
    "        file = open(processedTrainDataSet, 'rb')\n",
    "        train_image_array, train_image_labels = pickle.load(file)\n",
    "        file.close()\n",
    "        print(\"Done Loading Train DataSet.\")\n",
    "        \n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"Processed_DataSet/CroatianTrainDataSet.pkl file does not exist\")\n",
    "        print(\"Loading Train DataSet ... This may take a while.\")\n",
    "        train_image_array, train_image_labels =  LoadCroatianTrainDataSet()\n",
    "        file = open(processedTrainDataSet, 'wb')\n",
    "        pickle.dump((train_image_array, train_image_labels), file, protocol=4)\n",
    "        file.close()\n",
    "        print(\"Saving pre-processed train DataSets in Processed_DataSet/CroatianTrainDataSet.pkl\")\n",
    "    return train_image_array, train_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7NesrbLMTHxc"
   },
   "outputs": [],
   "source": [
    "def ReadTestDataSet():\n",
    "    processedTestDataSet = '../DataSet/Processed_DataSet/CroatianTestDataSet.pkl'\n",
    "    isProcessedTestDataSetExits= os.path.exists(processedTestDataSet)\n",
    "    test_image_array, test_image_labels = None, None\n",
    "    \n",
    "    if isProcessedTestDataSetExits:\n",
    "        print(\"Loading Processed Test DataSet from Processed_DataSet/CroatianTestDataSet.pkl\")\n",
    "        file = open(processedTestDataSet, 'rb')\n",
    "        test_image_array, test_image_labels = pickle.load(file)\n",
    "        file.close()\n",
    "        print(\"Done Loading Test DataSet.\")\n",
    "    else:\n",
    "        print(\"Processed_DataSet/CroatianTestDataSet.pkl file does not exist\")\n",
    "        print(\"Loading Test DataSet ... This may take a while.\")\n",
    "        test_image_array, test_image_labels = LoadCroatianTestDataSet()\n",
    "        file = open(processedTestDataSet, 'wb')\n",
    "        pickle.dump((test_image_array, test_image_labels), file)\n",
    "        file.close()\n",
    "        print(\"Saving pre-processed test DataSets in Processed_DataSet/CroatianTestDataSet.pkl\")\n",
    "    return test_image_array, test_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "nwb9DA_BTHxi",
    "outputId": "4eb702df-2e98-402f-bc13-9a690e46d18c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Train Pre-processed DataSet\n",
      "Loading Processed Train DataSet from Processed_DataSet/CroatianTrainDataSet.pkl\n",
      "Done Loading Train DataSet.\n"
     ]
    }
   ],
   "source": [
    "train_image_array, train_image_labels= ReadTrainDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lg4WjgWaTHxo",
    "outputId": "157c7af9-ec4d-4b64-d394-7db7375275ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4044, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xucZh2z0THxt",
    "outputId": "52eb5c52-b130-41b7-b66b-828d02f3a57b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Processed Test DataSet from Processed_DataSet/CroatianTestDataSet.pkl\n",
      "Done Loading Test DataSet.\n"
     ]
    }
   ],
   "source": [
    "test_image_array, test_image_labels= ReadTestDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "irXzfe0UTHx1",
    "outputId": "7efd9540-79da-421c-b8ab-f6a796cbb2ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1784, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_image_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDjTv6ZiTHyL"
   },
   "source": [
    "## Train-Split \n",
    "Split Train images dataset into two splits: training and validation respectively 90-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-q969YRTHyN"
   },
   "outputs": [],
   "source": [
    "image_train, image_valid,label_train, label_valid = train_test_split(train_image_array, train_image_labels,stratify=train_image_labels,test_size=0.1,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nF2vdbY8THyT",
    "outputId": "f7319d75-3e2b-4de7-d12c-ef7a7d1f0dce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3639, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "print(image_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_qdOQZJmTHya"
   },
   "outputs": [],
   "source": [
    "del train_image_array\n",
    "del train_image_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ayljfn89THyf"
   },
   "source": [
    "## Hyper-parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hZUbJowTHyg"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters tuning\n",
    "kernel_2 = (3,3)\n",
    "pooling = (2,2)\n",
    "dropout = 0.3\n",
    "num_classes = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQmS_iLBTHyl"
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJvjlvWOTHyn"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,SpatialDropout2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Add,AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, SeparableConv2D,BatchNormalization,Dropout,MaxPool2D,Flatten,Dense\n",
    "from keras.layers import concatenate\n",
    "\n",
    "from keras import initializers\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JqkWU3jsTHys"
   },
   "outputs": [],
   "source": [
    "weight_decay=1E-4\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def model_():\n",
    "    model = None\n",
    "    tf.initializers.Orthogonal(gain=1.0, seed=None)\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(32,(5,5), input_shape=(60,60,1), strides = 1, padding='valid',activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32,(3,3), activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64,(5,5), strides = 1, padding='valid', activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64,(3,3), activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256,(5,5), strides = 1, padding='valid', activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(256,kernel_2, activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "    model.add(MaxPool2D(pooling))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = tf.nn.relu,kernel_regularizer=l2(0.1)))\n",
    "   \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuc_8rERTHyx"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = model_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0wgJBvnTHy0"
   },
   "source": [
    "## Model Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK82asmNelMa"
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=2,  verbose=1, min_delta=1e-4, min_lr=1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqKXVwUETHy1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dg8u_6ZgTHy5"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "aug = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            \n",
    "                           \n",
    "                            rotation_range=10.,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38QMwlN1THy-"
   },
   "outputs": [],
   "source": [
    "x=aug.flow(image_train, np.array(label_train), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0Ec91mMTHzE"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x, epochs=50, shuffle=True, validation_data=(image_valid, np.array(label_valid)),verbose=1,callbacks=[reduce_lr])             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBRcx6heTHzM"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "YHv1oxvH1jx6",
    "outputId": "f89a1045-e3b1-4dc0-af01-c44a4111737b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 32ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16686005890369415, 0.9955157041549683]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_image_array, np.array(test_image_labels), batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIyUGX4fTHzR"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P78F9THYTHzS"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjhuW2nWTHzW"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FngFpjsXTHzZ"
   },
   "source": [
    "## Model Summary \n",
    "Number of parameters used in the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHfSKmEcTHzc"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "phBM_WPuTHzg"
   },
   "source": [
    "## Saving Trained .h5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNjCliQyTHzh"
   },
   "outputs": [],
   "source": [
    "def saveCNNModel(model_name):\n",
    "    model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2RME079THzk"
   },
   "outputs": [],
   "source": [
    "saveCNNModel('Trained_Models/Croatian_Winning_99_55.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYr5UPITTHzo"
   },
   "outputs": [],
   "source": [
    "model._set_inputs(image_train,np.array(label_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7hzL2wdTHzr"
   },
   "source": [
    "## Loading Saved Trained .h5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-hjEIw8THzt"
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HtTAFeDGTHzx"
   },
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    Model = tf.keras.models.load_model('Trained_Models/Croatian_Winning_99_55.h5')\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrQFJlGBTHz0"
   },
   "outputs": [],
   "source": [
    "model= load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQQOHjXWTHz3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lRb1yZeTHz6"
   },
   "source": [
    "## Computation Avg. Processing Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ch1eEhDJTHz8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "model.predict(test_image_array)\n",
    "t2=time.time()\n",
    "print(\"Average Processing time: \", ((t2-t1)/12630)*1000, \" ms\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gIyUGX4fTHzR",
    "FngFpjsXTHzZ",
    "h7hzL2wdTHzr",
    "2lRb1yZeTHz6"
   ],
   "name": " Croatian_Model_PlayGround_99_55_less_loss_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
