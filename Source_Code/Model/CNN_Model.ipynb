{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IntialiseEnv():\n",
    "    nb_dir = os.path.split(os.getcwd())[0]\n",
    "    if nb_dir not in sys.path:\n",
    "        sys.path.append(nb_dir)\n",
    "    invalid_path='/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "    if invalid_path in sys.path:\n",
    "        sys.path.remove(invalid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/rana/Documents/Deep_Learning/Project/Traffic_Sign_Recognition_Detection/Source_Code/Data_Preparation/Data_Preparation.ipynb\n",
      "importing Jupyter notebook from /home/rana/Documents/Deep_Learning/Project/Traffic_Sign_Recognition_Detection/Source_Code/Feature_Extraction/Segmentation.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import sys\n",
    "IntialiseEnv()\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import import_ipynb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Data_Preparation.Data_Preparation import LoadTrainDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU/CPU Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.conv_layer_1 = tf.keras.layers.Conv2D(filter_size,kernel_1, strides = 1, padding='same',activation = tf.nn.relu)\n",
    "        self.pool_layer_1 = tf.keras.layers.MaxPool2D(pooling)\n",
    "        self.conv_layer_2 = tf.keras.layers.Conv2D(filter_size,kernel_2, strides = 1, padding='same', activation = tf.nn.relu)\n",
    "        self.pool_layer_2 = tf.keras.layers.MaxPool2D(pooling)\n",
    "        self.conv_layer_3 = tf.keras.layers.Conv2D(filter_size,kernel_2, strides = 1, padding='same', activation = tf.nn.relu)\n",
    "        self.pool_layer_3 = tf.keras.layers.MaxPool2D(pooling)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = tf.keras.layers.Dense(hidden_layer, activation = tf.nn.relu)\n",
    "        self.drop = tf.keras.layers.Dropout(dropout)\n",
    "        self.final = tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv_layer_1(input_tensor)\n",
    "        x = self.pool_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.pool_layer_2(x)        \n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.pool_layer_3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_init_fn, optimizer_init_fn, num_epochs=1,TrainDataSet, is_training=False):  \n",
    "\n",
    "        # Compute the loss like we did in Part II\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            train_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            \n",
    "            # Training DataSet\n",
    "            for x_np, y_np in TrainDataSet:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_states()\n",
    "                        val_accuracy.reset_states()\n",
    "                        for test_x, test_y in ValidationDataSet:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters tuning\n",
    "kernel_1 = (5,5)\n",
    "kernel_2 = (3,3)\n",
    "pooling = (2,2)\n",
    "filter_size = 32\n",
    "hidden_layer = 64\n",
    "dropout = 0.3\n",
    "num_classes = 43\n",
    "\n",
    "# Configurations of batch printing\n",
    "print_every = 1000\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.Adam(learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel():\n",
    "    model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSetImages, DataSetLabels = LoadTrainDataSet()\n",
    "image_train, image_valid,label_train, label_valid=train_test_split(DataSetImages,DataSetLabels,stratify=y,test_size=0.33,random_state=42)\n",
    "TrainDataSet = image_train, label_train\n",
    "ValidationDataSet = image_valid, label_valid\n",
    "train(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, TrainDataSet,ValidationDataSet, is_training=True)\n",
    "saveCNNModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
