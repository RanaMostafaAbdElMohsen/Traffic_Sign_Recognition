{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-muCywGHH-K0"
   },
   "outputs": [],
   "source": [
    "def IntialiseEnv():\n",
    "    nb_dir = os.path.split(os.getcwd())[0]\n",
    "    if nb_dir not in sys.path:\n",
    "        sys.path.append(nb_dir)\n",
    "    invalid_path='/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "    if invalid_path in sys.path:\n",
    "        sys.path.remove(invalid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCs4OOV1H-Lj"
   },
   "outputs": [],
   "source": [
    "## Import libraries need to be imported, Dont forget to update requirements.txt!\n",
    "import os\n",
    "import sys\n",
    "IntialiseEnv()\n",
    "import numpy as np\n",
    "import cv2\n",
    "import skimage.color\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "import random\n",
    "from PIL import Image\n",
    "import scipy, scipy.misc, scipy.signal\n",
    "from skimage import color, data, restoration\n",
    "from skimage.util import random_noise\n",
    "from skimage import exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IzVEUusuMAy"
   },
   "outputs": [],
   "source": [
    "def motion_blur(img):\n",
    "  \n",
    "  size = 15\n",
    "\n",
    "  # generating the kernel\n",
    "  kernel_motion_blur = np.zeros((size, size))\n",
    "  kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
    "  kernel_motion_blur = kernel_motion_blur / size\n",
    "\n",
    "  # applying the kernel to the input image\n",
    "  output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBqC4ZEAuM1v"
   },
   "outputs": [],
   "source": [
    "def motion_blur_horizontal_vertical(img):\n",
    "  \n",
    "\n",
    "  kernel_size = 30\n",
    "  \n",
    "  # Create the vertical kernel. \n",
    "  kernel_v = np.zeros((kernel_size, kernel_size)) \n",
    "    \n",
    "  # Create a copy of the same for creating the horizontal kernel. \n",
    "  kernel_h = np.copy(kernel_v) \n",
    "    \n",
    "  # Fill the middle row with ones. \n",
    "  kernel_v[:, int((kernel_size - 1)/2)] = np.ones(kernel_size) \n",
    "  kernel_h[int((kernel_size - 1)/2), :] = np.ones(kernel_size) \n",
    "    \n",
    "  # Normalize. \n",
    "  kernel_v /= kernel_size \n",
    "  kernel_h /= kernel_size \n",
    "    \n",
    "  # Apply the vertical kernel. \n",
    "  vertical_mb = cv2.filter2D(img, -1, kernel_v) \n",
    "    \n",
    "  # Apply the horizontal kernel. \n",
    "  horizonal_mb = cv2.filter2D(img, -1, kernel_h) \n",
    "  return horizonal_mb,vertical_mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVj6BPwjIHO7"
   },
   "outputs": [],
   "source": [
    "def computeTextureWeights(fin, sigma, sharpness):\n",
    "    dt0_v = np.vstack((np.diff(fin, n=1, axis=0), fin[0,:]-fin[-1,:]))\n",
    "    dt0_h = np.vstack((np.diff(fin, n=1, axis=1).conj().T, fin[:,0].conj().T-fin[:,-1].conj().T)).conj().T\n",
    "\n",
    "    gauker_h = scipy.signal.convolve2d(dt0_h, np.ones((1,sigma)), mode='same')\n",
    "    gauker_v = scipy.signal.convolve2d(dt0_v, np.ones((sigma,1)), mode='same')\n",
    "\n",
    "    W_h = 1/(np.abs(gauker_h)*np.abs(dt0_h)+sharpness)\n",
    "    W_v = 1/(np.abs(gauker_v)*np.abs(dt0_v)+sharpness)\n",
    "\n",
    "    return  W_h, W_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytXI0ImCIJWM"
   },
   "outputs": [],
   "source": [
    "def solveLinearEquation(IN, wx, wy, lamda):\n",
    "    [r, c] = IN.shape\n",
    "    k = r * c\n",
    "    dx =  -lamda * wx.flatten('F')\n",
    "    dy =  -lamda * wy.flatten('F')\n",
    "    tempx = np.roll(wx, 1, axis=1)\n",
    "    tempy = np.roll(wy, 1, axis=0)\n",
    "    dxa = -lamda *tempx.flatten('F')\n",
    "    dya = -lamda *tempy.flatten('F')\n",
    "    tmp = wx[:,-1]\n",
    "    tempx = np.concatenate((tmp[:,None], np.zeros((r,c-1))), axis=1)\n",
    "    tmp = wy[-1,:]\n",
    "    tempy = np.concatenate((tmp[None,:], np.zeros((r-1,c))), axis=0)\n",
    "    dxd1 = -lamda * tempx.flatten('F')\n",
    "    dyd1 = -lamda * tempy.flatten('F')\n",
    "    \n",
    "    wx[:,-1] = 0\n",
    "    wy[-1,:] = 0\n",
    "    dxd2 = -lamda * wx.flatten('F')\n",
    "    dyd2 = -lamda * wy.flatten('F')\n",
    "    \n",
    "    Ax = scipy.sparse.spdiags(np.concatenate((dxd1[:,None], dxd2[:,None]), axis=1).T, np.array([-k+r,-r]), k, k)\n",
    "    Ay = scipy.sparse.spdiags(np.concatenate((dyd1[None,:], dyd2[None,:]), axis=0), np.array([-r+1,-1]), k, k)\n",
    "    D = 1 - ( dx + dy + dxa + dya)\n",
    "    A = ((Ax+Ay) + (Ax+Ay).conj().T + scipy.sparse.spdiags(D, 0, k, k)).T\n",
    "    \n",
    "    tin = IN[:,:]\n",
    "    tout = scipy.sparse.linalg.spsolve(A, tin.flatten('F'))\n",
    "    OUT = np.reshape(tout, (r, c), order='F')\n",
    "    \n",
    "    return OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vyQCtv6ILg7"
   },
   "outputs": [],
   "source": [
    "def tsmooth(img, lamda=0.01, sigma=3.0, sharpness=0.001):\n",
    "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "    x = np.copy(I)\n",
    "    wx, wy = computeTextureWeights(x, sigma, sharpness)\n",
    "    S = solveLinearEquation(I, wx, wy, lamda)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJOn8w-EINFn"
   },
   "outputs": [],
   "source": [
    "def rgb2gm(I):\n",
    "    if (I.shape[2] == 3):\n",
    "        I = cv2.normalize(I.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "        I = np.abs((I[:,:,0]*I[:,:,1]*I[:,:,2]))**(1/3)\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UtfKhPhVIO4M"
   },
   "outputs": [],
   "source": [
    "def applyK(I, k, a=-0.3293, b=1.1258):\n",
    "    f = lambda x: np.exp((1-x**a)*b)\n",
    "    beta = f(k)\n",
    "    gamma = k**a\n",
    "    J = (I**gamma)*beta\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwY44M6TIQj-"
   },
   "outputs": [],
   "source": [
    "def entropy(X):\n",
    "    tmp = X * 255\n",
    "    tmp[tmp > 255] = 255\n",
    "    tmp[tmp<0] = 0\n",
    "    tmp = tmp.astype(np.uint8)\n",
    "    _, counts = np.unique(tmp, return_counts=True)\n",
    "    pk = np.asarray(counts)\n",
    "    pk = 1.0*pk / np.sum(pk, axis=0)\n",
    "    S = -np.sum(pk * np.log2(pk), axis=0)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrXVQ3qGISnd"
   },
   "outputs": [],
   "source": [
    "def maxEntropyEnhance(I, isBad, a=-0.3293, b=1.1258):\n",
    "    # Esatimate k\n",
    "    tmp = cv2.resize(I, (50,50), interpolation=cv2.INTER_AREA)\n",
    "    tmp[tmp<0] = 0\n",
    "    tmp = tmp.real\n",
    "    Y = rgb2gm(tmp)\n",
    "    \n",
    "    isBad = isBad * 1\n",
    "    # isBad = scipy.misc.imresize(isBad, (50,50), interp='bicubic', mode='F')\n",
    "    isBad = np.array(Image.fromarray(isBad,mode='F').resize((50, 50), resample=Image.BICUBIC))\n",
    "    # isBad =  cv2.resize(isBad, (50,50), interpolation = cv2.INTER_CUBIC)\n",
    "    isBad[isBad<0.5] = 0\n",
    "    isBad[isBad>=0.5] = 1\n",
    "    Y = Y[isBad==1]\n",
    "    \n",
    "    if Y.size == 0:\n",
    "       J = I\n",
    "       return J\n",
    "    \n",
    "    f = lambda k: -entropy(applyK(Y, k))\n",
    "    opt_k = scipy.optimize.fminbound(f, 1, 7)\n",
    "    \n",
    "    # Apply k\n",
    "    J = applyK(I, opt_k, a, b) - 0.01\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxN_PTNRIWFN"
   },
   "outputs": [],
   "source": [
    "def Ying_2017_CAIP(img, mu=0.5, a=-0.3293, b=1.1258):\n",
    "    lamda = 0.5\n",
    "    sigma = 5\n",
    "    I = cv2.normalize(img.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Weight matrix estimation\n",
    "    t_b = np.max(I, axis=2)\n",
    "    h_,w_=t_b.shape\n",
    "    w_= int(w_*0.5)\n",
    "    h_ =int(h_*0.5)\n",
    "    # t_b_resized = np.array(Image.fromarray(t_b, mode='F').resize((40, 40), resample=Image.BICUBIC))\n",
    "    # t_b_resized =  cv2.resize(t_b, (w_,h_), interpolation = cv2.INTER_CUBIC)\n",
    "    t_b_new= np.asarray(Image.fromarray(t_b , mode='F').resize((w_,h_), resample=Image.BICUBIC))\n",
    "    t_our = cv2.resize(tsmooth(t_b_new, lamda, sigma), (t_b.shape[1], t_b.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    # t_our = cv2.resize(tsmooth(scipy.misc.imresize(t_b, 0.5, interp='bicubic', mode='F'), lamda, sigma), (t_b.shape[1], t_b.shape[0]), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Apply camera model with k(exposure ratio)\n",
    "    isBad = t_our < 0.5\n",
    "    J = maxEntropyEnhance(I, isBad)\n",
    "\n",
    "    # W: Weight Matrix\n",
    "    t = np.zeros((t_our.shape[0], t_our.shape[1], I.shape[2]))\n",
    "    for i in range(I.shape[2]):\n",
    "        t[:,:,i] = t_our\n",
    "    W = t**mu\n",
    "\n",
    "    I2 = I*W\n",
    "    J2 = J*(1-W)\n",
    "\n",
    "    result = I2 + J2\n",
    "    result = result * 255\n",
    "    result[result > 255] = 255\n",
    "    result[result<0] = 0\n",
    "    return result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_P6ESy1BH-Lq"
   },
   "outputs": [],
   "source": [
    "## Read image in path\n",
    "def readImage(path):\n",
    "    return cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oODU23VNH-Lw"
   },
   "outputs": [],
   "source": [
    "def loadSampleImg(path):\n",
    "    img=readImage(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img=cv2.resize(img,(80,80))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jrt9Ni4qH-L0"
   },
   "outputs": [],
   "source": [
    "## Sharpen Image\n",
    "def sharpen(img):\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    im = cv2.filter2D(img, -1, kernel)\n",
    "    plt.imshow(im)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nt6qU01OH-L6"
   },
   "outputs": [],
   "source": [
    "# Excessive sharpening image\n",
    "def excessive(img):\n",
    "    kernel = np.array([[1,1,1], [1,-7,1], [1,1,1]])\n",
    "    im = cv2.filter2D(img, -1, kernel)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d52hmkdzH-L-"
   },
   "outputs": [],
   "source": [
    "# Blur of images\n",
    "def blur(img):\n",
    "    blur =  cv2.medianBlur(img,5)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbvDQv3VH-MC"
   },
   "outputs": [],
   "source": [
    "# Edge Enhancement\n",
    "def edgeEnhancement(img):\n",
    "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "                               [-1,2,2,2,-1],\n",
    "                               [-1,2,8,2,-1],\n",
    "                               [-2,2,2,2,-1],\n",
    "                               [-1,-1,-1,-1,-1]])/8.0\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    image=cv2.filter2D(img, -1, kernel)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bkDwuVSH-MG"
   },
   "outputs": [],
   "source": [
    "# Weight image with another image\n",
    "def addWeightedImg(img,blur):\n",
    "    result = cv2.addWeighted(img, 1, blur, -0.5, 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpsw_Pl-H-MJ"
   },
   "outputs": [],
   "source": [
    "# Contrast Enhancement\n",
    "def ContrastEnhancement():\n",
    "    hsvImg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsvImg[...,1] = hsvImg[...,1]*1.6\n",
    "    hsvImg[...,2] = hsvImg[...,2]*0.8\n",
    "    img=cv2.cvtColor(hsvImg,cv2.COLOR_HSV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaZgJJUlH-MO"
   },
   "outputs": [],
   "source": [
    "#Edge Detection\n",
    "def CannyEdgeDetection(img):\n",
    "    edged=cv2.Canny(img,60,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DviMt_tWH-MR"
   },
   "outputs": [],
   "source": [
    "# Find Contours\n",
    "def FindContours(edged):\n",
    "    contours, hierarchy=cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    cv2.drawContours(img,contours,-1,(0,255,0),1)\n",
    "    ret =40\n",
    "    img[img>ret]=255\n",
    "    img[img<=ret]=0\n",
    "    img =cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c67iBKMiH-MU"
   },
   "outputs": [],
   "source": [
    "def Convert2Grayscale(img):\n",
    "    return skimage.color.rgb2gray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Th3SCu_H-MX"
   },
   "outputs": [],
   "source": [
    "def ThresholdSegmentationOtsu(img):\n",
    "    t = skimage.filters.threshold_otsu(img)\n",
    "    mask = img > t\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jIm_kaYKH-Mb"
   },
   "outputs": [],
   "source": [
    "def RemoveNoiseColouredImg(img):\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01iOug1FH-Me"
   },
   "outputs": [],
   "source": [
    "def HistogramEqualization(img):\n",
    "    img_to_yuv = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
    "    img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])\n",
    "    return cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yB-CjBa8H-Mj"
   },
   "outputs": [],
   "source": [
    "def CalculateContrast(img):\n",
    "    # convert to LAB color space\n",
    "    lab = cv2.cvtColor(img,cv2.COLOR_RGB2LAB)\n",
    "\n",
    "    # separate channels\n",
    "    L,A,B=cv2.split(lab)\n",
    "\n",
    "    # compute minimum and maximum in 5x5 region using erode and dilate\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    min = cv2.erode(L,kernel,iterations = 1)\n",
    "    max = cv2.dilate(L,kernel,iterations = 1)\n",
    "\n",
    "    # convert min and max to floats\n",
    "    min = min.astype(np.float64) \n",
    "    max = max.astype(np.float64) \n",
    "\n",
    "    # compute local contrast\n",
    "    contrast = (max-min)/(max+min)\n",
    "\n",
    "    # get average across whole image\n",
    "    average_contrast = 100*np.mean(contrast)\n",
    "\n",
    "    print(str(average_contrast)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFIx7-VkH-Mm"
   },
   "outputs": [],
   "source": [
    "def from_pil(pimg):\n",
    "    pimg = pimg.convert(mode='RGB')\n",
    "    nimg = np.asarray(pimg)\n",
    "    nimg.flags.writeable = True\n",
    "    return nimg\n",
    "\n",
    "def to_pil(nimg):\n",
    "    return Image.fromarray(np.uint8(nimg))\n",
    "\n",
    "def stretch_pre(nimg):\n",
    "    \"\"\"\n",
    "    from 'Applicability Of White-Balancing Algorithms to Restoring Faded Colour Slides: An Empirical Evaluation'\n",
    "    \"\"\"\n",
    "    nimg = nimg.transpose(2, 0, 1)\n",
    "    nimg[0] = np.maximum(nimg[0]-nimg[0].min(),0)\n",
    "    nimg[1] = np.maximum(nimg[1]-nimg[1].min(),0)\n",
    "    nimg[2] = np.maximum(nimg[2]-nimg[2].min(),0)\n",
    "    return nimg.transpose(1, 2, 0)\n",
    "\n",
    "def grey_world(nimg):\n",
    "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
    "    mu_g = np.average(nimg[1])\n",
    "    nimg[0] = np.minimum(nimg[0]*(mu_g/np.average(nimg[0])),255)\n",
    "    nimg[2] = np.minimum(nimg[2]*(mu_g/np.average(nimg[2])),255)\n",
    "    return  nimg.transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "def max_white(nimg):\n",
    "    if nimg.dtype==np.uint8:\n",
    "        brightest=float(2**8)\n",
    "    elif nimg.dtype==np.uint16:\n",
    "        brightest=float(2**16)\n",
    "    elif nimg.dtype==np.uint32:\n",
    "        brightest=float(2**32)\n",
    "    else:\n",
    "        brightest==float(2**8)\n",
    "    nimg = nimg.transpose(2, 0, 1)\n",
    "    nimg = nimg.astype(np.int32)\n",
    "    nimg[0] = np.minimum(nimg[0] * (brightest/float(nimg[0].max())),255)\n",
    "    nimg[1] = np.minimum(nimg[1] * (brightest/float(nimg[1].max())),255)\n",
    "    nimg[2] = np.minimum(nimg[2] * (brightest/float(nimg[2].max())),255)\n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "def stretch(nimg):\n",
    "    return max_white(stretch_pre(nimg))\n",
    "\n",
    "def retinex(nimg):\n",
    "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
    "    mu_g = nimg[1].max()\n",
    "    nimg[0] = np.minimum(nimg[0]*(mu_g/float(nimg[0].max())),255)\n",
    "    nimg[2] = np.minimum(nimg[2]*(mu_g/float(nimg[2].max())),255)\n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "def retinex_adjust(nimg):\n",
    "    \"\"\"\n",
    "    from 'Combining Gray World and Retinex Theory for Automatic White Balance in Digital Photography'\n",
    "    \"\"\"\n",
    "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
    "    sum_r = np.sum(nimg[0])\n",
    "    sum_r2 = np.sum(nimg[0]**2)\n",
    "    max_r = nimg[0].max()\n",
    "    max_r2 = max_r**2\n",
    "    sum_g = np.sum(nimg[1])\n",
    "    max_g = nimg[1].max()\n",
    "    coefficient = np.linalg.solve(np.array([[sum_r2,sum_r],[max_r2,max_r]]),\n",
    "                                  np.array([sum_g,max_g]))\n",
    "    nimg[0] = np.minimum((nimg[0]**2)*coefficient[0] + nimg[0]*coefficient[1],255)\n",
    "    sum_b = np.sum(nimg[1])\n",
    "    sum_b2 = np.sum(nimg[1]**2)\n",
    "    max_b = nimg[1].max()\n",
    "    max_b2 = max_r**2\n",
    "    coefficient = np.linalg.solve(np.array([[sum_b2,sum_b],[max_b2,max_b]]),\n",
    "                                             np.array([sum_g,max_g]))\n",
    "    nimg[1] = np.minimum((nimg[1]**2)*coefficient[0] + nimg[1]*coefficient[1],255)\n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "def retinex_with_adjust(nimg):\n",
    "    return retinex_adjust(retinex(nimg))\n",
    "\n",
    "def standard_deviation_weighted_grey_world(nimg,subwidth,subheight):\n",
    "    \"\"\"\n",
    "    This function does not work correctly\n",
    "    \"\"\"\n",
    "    nimg = nimg.astype(np.uint32)\n",
    "    height, width,ch = nimg.shape\n",
    "    strides = nimg.itemsize*np.array([width*subheight,subwidth,width,3,1])\n",
    "    shape = (height/subheight, width/subwidth, subheight, subwidth,3)\n",
    "    blocks = np.lib.stride_tricks.as_strided(nimg, shape=shape, strides=strides)\n",
    "    y,x = blocks.shape[:2]\n",
    "    std_r = np.zeros([y,x],dtype=np.float16)\n",
    "    std_g = np.zeros([y,x],dtype=np.float16)\n",
    "    std_b = np.zeros([y,x],dtype=np.float16)\n",
    "    std_r_sum = 0.0\n",
    "    std_g_sum = 0.0\n",
    "    std_b_sum = 0.0\n",
    "    for i in xrange(y):\n",
    "        for j in xrange(x):\n",
    "            subblock = blocks[i,j]\n",
    "            subb = subblock.transpose(2, 0, 1)\n",
    "            std_r[i,j]=np.std(subb[0])\n",
    "            std_g[i,j]=np.std(subb[1])\n",
    "            std_b[i,j]=np.std(subb[2])\n",
    "            std_r_sum += std_r[i,j]\n",
    "            std_g_sum += std_g[i,j]\n",
    "            std_b_sum += std_b[i,j]\n",
    "    sdwa_r = 0.0\n",
    "    sdwa_g = 0.0\n",
    "    sdwa_b = 0.0\n",
    "    for i in xrange(y):\n",
    "        for j in xrange(x):\n",
    "            subblock = blocks[i,j]\n",
    "            subb = subblock.transpose(2, 0, 1)\n",
    "            mean_r=np.mean(subb[0])\n",
    "            mean_g=np.mean(subb[1])\n",
    "            mean_b=np.mean(subb[2])\n",
    "            sdwa_r += (std_r[i,j]/std_r_sum)*mean_r\n",
    "            sdwa_g += (std_g[i,j]/std_g_sum)*mean_g\n",
    "            sdwa_b += (std_b[i,j]/std_b_sum)*mean_b\n",
    "    sdwa_avg = (sdwa_r+sdwa_g+sdwa_b)/3\n",
    "    gain_r = sdwa_avg/sdwa_r\n",
    "    gain_g = sdwa_avg/sdwa_g\n",
    "    gain_b = sdwa_avg/sdwa_b\n",
    "    nimg = nimg.transpose(2, 0, 1)\n",
    "    nimg[0] = np.minimum(nimg[0]*gain_r,255)\n",
    "    nimg[1] = np.minimum(nimg[1]*gain_g,255)\n",
    "    nimg[2] = np.minimum(nimg[2]*gain_b,255)\n",
    "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMzF8_lQH-Mp"
   },
   "outputs": [],
   "source": [
    "# Final Feature Extraction Algo\n",
    "# See if there any room for improvements\n",
    "# See if colour consistency make any changes for real\n",
    "def FeatureExtraction(img):\n",
    "\n",
    "    img = Ying_2017_CAIP(img)\n",
    "    pil_image=to_pil(retinex((img)))\n",
    "    open_cv_image = np.array(pil_image) \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
    "    edgeEnhanced=edgeEnhancement(hist_equalization_result)\n",
    "    gray= Convert2Grayscale(edgeEnhanced)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-vIAo-KH-Ms"
   },
   "outputs": [],
   "source": [
    "def FeatureExtractionWithoutGrayScaleConversion(img):\n",
    "    img = Ying_2017_CAIP(img)\n",
    "    pil_image=to_pil(retinex((img)))\n",
    "    open_cv_image = np.array(pil_image) \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
    "    edgeEnhanced=edgeEnhancement(hist_equalization_result)/255\n",
    "    return edgeEnhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUz7IkDuH-My"
   },
   "outputs": [],
   "source": [
    "def FeatureExtractionHSV(img):\n",
    "    hsvImg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    return hsvImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XxPnSiTfH-M4"
   },
   "outputs": [],
   "source": [
    "def ProposedSegmentationAlgoWithDisplay(path): \n",
    "    img=loadSampleImg(path)\n",
    "    img = Ying_2017_CAIP(img)\n",
    "    pil_image=to_pil(retinex((img)))\n",
    "    open_cv_image = np.array(pil_image) \n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
    "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
    "    edgeEnhanced=edgeEnhancement(hist_equalization_result)\n",
    "    gray= Convert2Grayscale(edgeEnhanced)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4)\n",
    "    ax[0].imshow(img)\n",
    "    ax[1].imshow(hist_equalization_result)\n",
    "    ax[2].imshow(edgeEnhanced)\n",
    "    ax[3].imshow(gray)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jcG6wHTH-NA"
   },
   "outputs": [],
   "source": [
    "def rBrightness(image,ratio):\n",
    "    hsv=cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    brightness=np.float64(hsv[:, :, 2])\n",
    "    brightness=brightness*(1.0+np.random.uniform(-ratio,ratio))\n",
    "    brightness[brightness>255]=255\n",
    "    brightness[brightness<0]=0\n",
    "    hsv[:, :, 2]=brightness\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "def rRotation(image, angle):\n",
    "    if angle==0:\n",
    "        return image\n",
    "    angle=np.random.uniform(-angle,angle)\n",
    "    rows,cols=image.shape[:2]\n",
    "    size=rows,cols\n",
    "    center=rows/2,cols/2\n",
    "    scale=1.0\n",
    "    rotation=cv2.getRotationMatrix2D(center,angle,scale)\n",
    "    return cv2.warpAffine(image,rotation,size)\n",
    "def rTranslation(image, translation):\n",
    "    if translation==0:\n",
    "        return 0\n",
    "    rows,cols=image.shape[:2]\n",
    "    size=rows,cols\n",
    "    x=np.random.uniform(-translation,translation)\n",
    "    y=np.random.uniform(-translation,translation)\n",
    "    trans=np.float32([[1,0,x],[0,1,y]])\n",
    "    return cv2.warpAffine(image,trans,size)\n",
    "def rShear(image, shear):\n",
    "    if shear==0:\n",
    "        return image\n",
    "    rows,cols=image.shape[:2]\n",
    "    size=rows,cols\n",
    "    left,right,top,bottom=shear,cols-shear,shear,rows-shear\n",
    "    dx=np.random.uniform(-shear,shear)\n",
    "    dy=np.random.uniform(-shear,shear)\n",
    "    p1=np.float32([[left,top],[right,top],[left,bottom]])\n",
    "    p2=np.float32([[left+dx,top],[right+dx,top+dy],[left,bottom+dy]])\n",
    "    move=cv2.getAffineTransform(p1,p2)\n",
    "    return cv2.warpAffine(image,move,size)\n",
    "def augment_image(image,brightness,angle,translation,shear):\n",
    "    image=rBrightness(image,brightness)\n",
    "    image=rRotation(image,angle)\n",
    "    image=rTranslation(image,translation)\n",
    "    image=rShear(image,shear)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdI8-D_KV8TN"
   },
   "outputs": [],
   "source": [
    "def cv2_clipped_zoom(img, zoom_factor):\n",
    "    \"\"\"\n",
    "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
    "    the image without changing dimensions\n",
    "    Args:\n",
    "        img : Image array\n",
    "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2] # It's also the final desired shape\n",
    "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
    "\n",
    "    ### Crop only the part that will remain in the result (more efficient)\n",
    "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
    "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
    "    y2, x2 = y1 + height, x1 + width\n",
    "    bbox = np.array([y1,x1,y2,x2])\n",
    "    # Map back to original image coordinates\n",
    "    bbox = (bbox / zoom_factor).astype(np.int)\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Handle padding when downscaling\n",
    "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
    "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
    "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
    "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
    "\n",
    "    result = cv2.resize(cropped_img, (resize_width, resize_height))\n",
    "    result = np.pad(result, pad_spec, mode='constant')\n",
    "    assert result.shape[0] == height and result.shape[1] == width\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjZjra45V7o-"
   },
   "outputs": [],
   "source": [
    "def another_augment(img):\n",
    "  # image_with_random_noise = random_noise(img)\n",
    "  #play with the contrast\n",
    "  v_min, v_max = np.percentile(img, (0.2, 99.8))\n",
    "  better_contrast = exposure.rescale_intensity(img, in_range=(v_min, v_max))\n",
    "  gamma_img=exposure.adjust_gamma(better_contrast, gamma=0.4, gain=0.9)\n",
    "  horizontal_flip = gamma_img[:, ::-1]\n",
    "  vertical_flip = horizontal_flip[::-1, :]\n",
    "  img_final=cv2_clipped_zoom(vertical_flip,1.5)\n",
    "  return img_final\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SegmentationNew.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
