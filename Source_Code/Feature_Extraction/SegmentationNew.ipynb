{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegmentationNew.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-muCywGHH-K0",
        "colab": {}
      },
      "source": [
        "def IntialiseEnv():\n",
        "    nb_dir = os.path.split(os.getcwd())[0]\n",
        "    if nb_dir not in sys.path:\n",
        "        sys.path.append(nb_dir)\n",
        "    invalid_path='/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
        "    if invalid_path in sys.path:\n",
        "        sys.path.remove(invalid_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RCs4OOV1H-Lj",
        "colab": {}
      },
      "source": [
        "## Import libraries need to be imported, Dont forget to update requirements.txt!\n",
        "import os\n",
        "import sys\n",
        "IntialiseEnv()\n",
        "import numpy as np\n",
        "import cv2\n",
        "import skimage.color\n",
        "import skimage.filters\n",
        "import skimage.io\n",
        "import matplotlib.pyplot as plt\n",
        "import import_ipynb\n",
        "import random\n",
        "from PIL import Image\n",
        "import scipy, scipy.misc, scipy.signal\n",
        "from skimage import color, data, restoration\n",
        "from skimage.util import random_noise\n",
        "from skimage import exposure"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4IzVEUusuMAy",
        "colab": {}
      },
      "source": [
        "def motion_blur(img):\n",
        "  \n",
        "  size = 15\n",
        "\n",
        "  # generating the kernel\n",
        "  kernel_motion_blur = np.zeros((size, size))\n",
        "  kernel_motion_blur[int((size-1)/2), :] = np.ones(size)\n",
        "  kernel_motion_blur = kernel_motion_blur / size\n",
        "\n",
        "  # applying the kernel to the input image\n",
        "  output = cv2.filter2D(img, -1, kernel_motion_blur)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yBqC4ZEAuM1v",
        "colab": {}
      },
      "source": [
        "def motion_blur_horizontal_vertical(img):\n",
        "  \n",
        "\n",
        "  kernel_size = 30\n",
        "  \n",
        "  # Create the vertical kernel. \n",
        "  kernel_v = np.zeros((kernel_size, kernel_size)) \n",
        "    \n",
        "  # Create a copy of the same for creating the horizontal kernel. \n",
        "  kernel_h = np.copy(kernel_v) \n",
        "    \n",
        "  # Fill the middle row with ones. \n",
        "  kernel_v[:, int((kernel_size - 1)/2)] = np.ones(kernel_size) \n",
        "  kernel_h[int((kernel_size - 1)/2), :] = np.ones(kernel_size) \n",
        "    \n",
        "  # Normalize. \n",
        "  kernel_v /= kernel_size \n",
        "  kernel_h /= kernel_size \n",
        "    \n",
        "  # Apply the vertical kernel. \n",
        "  vertical_mb = cv2.filter2D(img, -1, kernel_v) \n",
        "    \n",
        "  # Apply the horizontal kernel. \n",
        "  horizonal_mb = cv2.filter2D(img, -1, kernel_h) \n",
        "  return horizonal_mb,vertical_mb\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RVj6BPwjIHO7",
        "colab": {}
      },
      "source": [
        "def computeTextureWeights(fin, sigma, sharpness):\n",
        "    dt0_v = np.vstack((np.diff(fin, n=1, axis=0), fin[0,:]-fin[-1,:]))\n",
        "    dt0_h = np.vstack((np.diff(fin, n=1, axis=1).conj().T, fin[:,0].conj().T-fin[:,-1].conj().T)).conj().T\n",
        "\n",
        "    gauker_h = scipy.signal.convolve2d(dt0_h, np.ones((1,sigma)), mode='same')\n",
        "    gauker_v = scipy.signal.convolve2d(dt0_v, np.ones((sigma,1)), mode='same')\n",
        "\n",
        "    W_h = 1/(np.abs(gauker_h)*np.abs(dt0_h)+sharpness)\n",
        "    W_v = 1/(np.abs(gauker_v)*np.abs(dt0_v)+sharpness)\n",
        "\n",
        "    return  W_h, W_v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytXI0ImCIJWM",
        "colab": {}
      },
      "source": [
        "def solveLinearEquation(IN, wx, wy, lamda):\n",
        "    [r, c] = IN.shape\n",
        "    k = r * c\n",
        "    dx =  -lamda * wx.flatten('F')\n",
        "    dy =  -lamda * wy.flatten('F')\n",
        "    tempx = np.roll(wx, 1, axis=1)\n",
        "    tempy = np.roll(wy, 1, axis=0)\n",
        "    dxa = -lamda *tempx.flatten('F')\n",
        "    dya = -lamda *tempy.flatten('F')\n",
        "    tmp = wx[:,-1]\n",
        "    tempx = np.concatenate((tmp[:,None], np.zeros((r,c-1))), axis=1)\n",
        "    tmp = wy[-1,:]\n",
        "    tempy = np.concatenate((tmp[None,:], np.zeros((r-1,c))), axis=0)\n",
        "    dxd1 = -lamda * tempx.flatten('F')\n",
        "    dyd1 = -lamda * tempy.flatten('F')\n",
        "    \n",
        "    wx[:,-1] = 0\n",
        "    wy[-1,:] = 0\n",
        "    dxd2 = -lamda * wx.flatten('F')\n",
        "    dyd2 = -lamda * wy.flatten('F')\n",
        "    \n",
        "    Ax = scipy.sparse.spdiags(np.concatenate((dxd1[:,None], dxd2[:,None]), axis=1).T, np.array([-k+r,-r]), k, k)\n",
        "    Ay = scipy.sparse.spdiags(np.concatenate((dyd1[None,:], dyd2[None,:]), axis=0), np.array([-r+1,-1]), k, k)\n",
        "    D = 1 - ( dx + dy + dxa + dya)\n",
        "    A = ((Ax+Ay) + (Ax+Ay).conj().T + scipy.sparse.spdiags(D, 0, k, k)).T\n",
        "    \n",
        "    tin = IN[:,:]\n",
        "    tout = scipy.sparse.linalg.spsolve(A, tin.flatten('F'))\n",
        "    OUT = np.reshape(tout, (r, c), order='F')\n",
        "    \n",
        "    return OUT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5vyQCtv6ILg7",
        "colab": {}
      },
      "source": [
        "def tsmooth(img, lamda=0.01, sigma=3.0, sharpness=0.001):\n",
        "    I = cv2.normalize(img.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    x = np.copy(I)\n",
        "    wx, wy = computeTextureWeights(x, sigma, sharpness)\n",
        "    S = solveLinearEquation(I, wx, wy, lamda)\n",
        "    return S"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJOn8w-EINFn",
        "colab": {}
      },
      "source": [
        "def rgb2gm(I):\n",
        "    if (I.shape[2] == 3):\n",
        "        I = cv2.normalize(I.astype('float64'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "        I = np.abs((I[:,:,0]*I[:,:,1]*I[:,:,2]))**(1/3)\n",
        "\n",
        "    return I"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UtfKhPhVIO4M",
        "colab": {}
      },
      "source": [
        "def applyK(I, k, a=-0.3293, b=1.1258):\n",
        "    f = lambda x: np.exp((1-x**a)*b)\n",
        "    beta = f(k)\n",
        "    gamma = k**a\n",
        "    J = (I**gamma)*beta\n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cwY44M6TIQj-",
        "colab": {}
      },
      "source": [
        "def entropy(X):\n",
        "    tmp = X * 255\n",
        "    tmp[tmp > 255] = 255\n",
        "    tmp[tmp<0] = 0\n",
        "    tmp = tmp.astype(np.uint8)\n",
        "    _, counts = np.unique(tmp, return_counts=True)\n",
        "    pk = np.asarray(counts)\n",
        "    pk = 1.0*pk / np.sum(pk, axis=0)\n",
        "    S = -np.sum(pk * np.log2(pk), axis=0)\n",
        "    return S"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrXVQ3qGISnd",
        "colab": {}
      },
      "source": [
        "def maxEntropyEnhance(I, isBad, a=-0.3293, b=1.1258):\n",
        "    # Esatimate k\n",
        "    tmp = cv2.resize(I, (50,50), interpolation=cv2.INTER_AREA)\n",
        "    tmp[tmp<0] = 0\n",
        "    tmp = tmp.real\n",
        "    Y = rgb2gm(tmp)\n",
        "    \n",
        "    isBad = isBad * 1\n",
        "    # isBad = scipy.misc.imresize(isBad, (50,50), interp='bicubic', mode='F')\n",
        "    isBad = np.array(Image.fromarray(isBad,mode='F').resize((50, 50), resample=Image.BICUBIC))\n",
        "    # isBad =  cv2.resize(isBad, (50,50), interpolation = cv2.INTER_CUBIC)\n",
        "    isBad[isBad<0.5] = 0\n",
        "    isBad[isBad>=0.5] = 1\n",
        "    Y = Y[isBad==1]\n",
        "    \n",
        "    if Y.size == 0:\n",
        "       J = I\n",
        "       return J\n",
        "    \n",
        "    f = lambda k: -entropy(applyK(Y, k))\n",
        "    opt_k = scipy.optimize.fminbound(f, 1, 7)\n",
        "    \n",
        "    # Apply k\n",
        "    J = applyK(I, opt_k, a, b) - 0.01\n",
        "    return J"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxN_PTNRIWFN",
        "colab": {}
      },
      "source": [
        "def Ying_2017_CAIP(img, mu=0.5, a=-0.3293, b=1.1258):\n",
        "    lamda = 0.5\n",
        "    sigma = 5\n",
        "    I = cv2.normalize(img.astype('float32'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "\n",
        "    # Weight matrix estimation\n",
        "    t_b = np.max(I, axis=2)\n",
        "    h_,w_=t_b.shape\n",
        "    w_= int(w_*0.5)\n",
        "    h_ =int(h_*0.5)\n",
        "    # t_b_resized = np.array(Image.fromarray(t_b, mode='F').resize((40, 40), resample=Image.BICUBIC))\n",
        "    # t_b_resized =  cv2.resize(t_b, (w_,h_), interpolation = cv2.INTER_CUBIC)\n",
        "    t_b_new= np.asarray(Image.fromarray(t_b , mode='F').resize((w_,h_), resample=Image.BICUBIC))\n",
        "    t_our = cv2.resize(tsmooth(t_b_new, lamda, sigma), (t_b.shape[1], t_b.shape[0]), interpolation=cv2.INTER_AREA)\n",
        "    # t_our = cv2.resize(tsmooth(scipy.misc.imresize(t_b, 0.5, interp='bicubic', mode='F'), lamda, sigma), (t_b.shape[1], t_b.shape[0]), interpolation=cv2.INTER_AREA)\n",
        "    \n",
        "    # Apply camera model with k(exposure ratio)\n",
        "    isBad = t_our < 0.5\n",
        "    J = maxEntropyEnhance(I, isBad)\n",
        "\n",
        "    # W: Weight Matrix\n",
        "    t = np.zeros((t_our.shape[0], t_our.shape[1], I.shape[2]))\n",
        "    for i in range(I.shape[2]):\n",
        "        t[:,:,i] = t_our\n",
        "    W = t**mu\n",
        "\n",
        "    I2 = I*W\n",
        "    J2 = J*(1-W)\n",
        "\n",
        "    result = I2 + J2\n",
        "    result = result * 255\n",
        "    result[result > 255] = 255\n",
        "    result[result<0] = 0\n",
        "    return result.astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_P6ESy1BH-Lq",
        "colab": {}
      },
      "source": [
        "## Read image in path\n",
        "def readImage(path):\n",
        "    return cv2.imread(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oODU23VNH-Lw",
        "colab": {}
      },
      "source": [
        "def loadSampleImg(path):\n",
        "    img=readImage(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img=cv2.resize(img,(80,80))\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jrt9Ni4qH-L0",
        "colab": {}
      },
      "source": [
        "## Sharpen Image\n",
        "def sharpen(img):\n",
        "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
        "    im = cv2.filter2D(img, -1, kernel)\n",
        "    plt.imshow(im)\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nt6qU01OH-L6",
        "colab": {}
      },
      "source": [
        "# Excessive sharpening image\n",
        "def excessive(img):\n",
        "    kernel = np.array([[1,1,1], [1,-7,1], [1,1,1]])\n",
        "    im = cv2.filter2D(img, -1, kernel)\n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d52hmkdzH-L-",
        "colab": {}
      },
      "source": [
        "# Blur of images\n",
        "def blur(img):\n",
        "    blur =  cv2.medianBlur(img,5)\n",
        "    return blur"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YbvDQv3VH-MC",
        "colab": {}
      },
      "source": [
        "# Edge Enhancement\n",
        "def edgeEnhancement(img):\n",
        "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
        "                               [-1,2,2,2,-1],\n",
        "                               [-1,2,8,2,-1],\n",
        "                               [-2,2,2,2,-1],\n",
        "                               [-1,-1,-1,-1,-1]])/8.0\n",
        "    img = cv2.filter2D(img, -1, kernel)\n",
        "    image=cv2.filter2D(img, -1, kernel)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_bkDwuVSH-MG",
        "colab": {}
      },
      "source": [
        "# Weight image with another image\n",
        "def addWeightedImg(img,blur):\n",
        "    result = cv2.addWeighted(img, 1, blur, -0.5, 0)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mpsw_Pl-H-MJ",
        "colab": {}
      },
      "source": [
        "# Contrast Enhancement\n",
        "def ContrastEnhancement():\n",
        "    hsvImg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    hsvImg[...,1] = hsvImg[...,1]*1.6\n",
        "    hsvImg[...,2] = hsvImg[...,2]*0.8\n",
        "    img=cv2.cvtColor(hsvImg,cv2.COLOR_HSV2RGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eaZgJJUlH-MO",
        "colab": {}
      },
      "source": [
        "#Edge Detection\n",
        "def CannyEdgeDetection(img):\n",
        "    edged=cv2.Canny(img,60,150)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DviMt_tWH-MR",
        "colab": {}
      },
      "source": [
        "# Find Contours\n",
        "def FindContours(edged):\n",
        "    contours, hierarchy=cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "    cv2.drawContours(img,contours,-1,(0,255,0),1)\n",
        "    ret =40\n",
        "    img[img>ret]=255\n",
        "    img[img<=ret]=0\n",
        "    img =cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c67iBKMiH-MU",
        "colab": {}
      },
      "source": [
        "def Convert2Grayscale(img):\n",
        "    return skimage.color.rgb2gray(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Th3SCu_H-MX",
        "colab": {}
      },
      "source": [
        "def ThresholdSegmentationOtsu(img):\n",
        "    t = skimage.filters.threshold_otsu(img)\n",
        "    mask = img > t\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jIm_kaYKH-Mb",
        "colab": {}
      },
      "source": [
        "def RemoveNoiseColouredImg(img):\n",
        "    dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "01iOug1FH-Me",
        "colab": {}
      },
      "source": [
        "def HistogramEqualization(img):\n",
        "    img_to_yuv = cv2.cvtColor(img,cv2.COLOR_RGB2YUV)\n",
        "    img_to_yuv[:,:,0] = cv2.equalizeHist(img_to_yuv[:,:,0])\n",
        "    return cv2.cvtColor(img_to_yuv, cv2.COLOR_YUV2RGB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yB-CjBa8H-Mj",
        "colab": {}
      },
      "source": [
        "def CalculateContrast(img):\n",
        "    # convert to LAB color space\n",
        "    lab = cv2.cvtColor(img,cv2.COLOR_RGB2LAB)\n",
        "\n",
        "    # separate channels\n",
        "    L,A,B=cv2.split(lab)\n",
        "\n",
        "    # compute minimum and maximum in 5x5 region using erode and dilate\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    min = cv2.erode(L,kernel,iterations = 1)\n",
        "    max = cv2.dilate(L,kernel,iterations = 1)\n",
        "\n",
        "    # convert min and max to floats\n",
        "    min = min.astype(np.float64) \n",
        "    max = max.astype(np.float64) \n",
        "\n",
        "    # compute local contrast\n",
        "    contrast = (max-min)/(max+min)\n",
        "\n",
        "    # get average across whole image\n",
        "    average_contrast = 100*np.mean(contrast)\n",
        "\n",
        "    print(str(average_contrast)+\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sFIx7-VkH-Mm",
        "colab": {}
      },
      "source": [
        "def from_pil(pimg):\n",
        "    pimg = pimg.convert(mode='RGB')\n",
        "    nimg = np.asarray(pimg)\n",
        "    nimg.flags.writeable = True\n",
        "    return nimg\n",
        "\n",
        "def to_pil(nimg):\n",
        "    return Image.fromarray(np.uint8(nimg))\n",
        "\n",
        "def stretch_pre(nimg):\n",
        "    \"\"\"\n",
        "    from 'Applicability Of White-Balancing Algorithms to Restoring Faded Colour Slides: An Empirical Evaluation'\n",
        "    \"\"\"\n",
        "    nimg = nimg.transpose(2, 0, 1)\n",
        "    nimg[0] = np.maximum(nimg[0]-nimg[0].min(),0)\n",
        "    nimg[1] = np.maximum(nimg[1]-nimg[1].min(),0)\n",
        "    nimg[2] = np.maximum(nimg[2]-nimg[2].min(),0)\n",
        "    return nimg.transpose(1, 2, 0)\n",
        "\n",
        "def grey_world(nimg):\n",
        "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
        "    mu_g = np.average(nimg[1])\n",
        "    nimg[0] = np.minimum(nimg[0]*(mu_g/np.average(nimg[0])),255)\n",
        "    nimg[2] = np.minimum(nimg[2]*(mu_g/np.average(nimg[2])),255)\n",
        "    return  nimg.transpose(1, 2, 0).astype(np.uint8)\n",
        "\n",
        "def max_white(nimg):\n",
        "    if nimg.dtype==np.uint8:\n",
        "        brightest=float(2**8)\n",
        "    elif nimg.dtype==np.uint16:\n",
        "        brightest=float(2**16)\n",
        "    elif nimg.dtype==np.uint32:\n",
        "        brightest=float(2**32)\n",
        "    else:\n",
        "        brightest==float(2**8)\n",
        "    nimg = nimg.transpose(2, 0, 1)\n",
        "    nimg = nimg.astype(np.int32)\n",
        "    nimg[0] = np.minimum(nimg[0] * (brightest/float(nimg[0].max())),255)\n",
        "    nimg[1] = np.minimum(nimg[1] * (brightest/float(nimg[1].max())),255)\n",
        "    nimg[2] = np.minimum(nimg[2] * (brightest/float(nimg[2].max())),255)\n",
        "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
        "\n",
        "def stretch(nimg):\n",
        "    return max_white(stretch_pre(nimg))\n",
        "\n",
        "def retinex(nimg):\n",
        "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
        "    mu_g = nimg[1].max()\n",
        "    nimg[0] = np.minimum(nimg[0]*(mu_g/float(nimg[0].max())),255)\n",
        "    nimg[2] = np.minimum(nimg[2]*(mu_g/float(nimg[2].max())),255)\n",
        "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
        "\n",
        "def retinex_adjust(nimg):\n",
        "    \"\"\"\n",
        "    from 'Combining Gray World and Retinex Theory for Automatic White Balance in Digital Photography'\n",
        "    \"\"\"\n",
        "    nimg = nimg.transpose(2, 0, 1).astype(np.uint32)\n",
        "    sum_r = np.sum(nimg[0])\n",
        "    sum_r2 = np.sum(nimg[0]**2)\n",
        "    max_r = nimg[0].max()\n",
        "    max_r2 = max_r**2\n",
        "    sum_g = np.sum(nimg[1])\n",
        "    max_g = nimg[1].max()\n",
        "    coefficient = np.linalg.solve(np.array([[sum_r2,sum_r],[max_r2,max_r]]),\n",
        "                                  np.array([sum_g,max_g]))\n",
        "    nimg[0] = np.minimum((nimg[0]**2)*coefficient[0] + nimg[0]*coefficient[1],255)\n",
        "    sum_b = np.sum(nimg[1])\n",
        "    sum_b2 = np.sum(nimg[1]**2)\n",
        "    max_b = nimg[1].max()\n",
        "    max_b2 = max_r**2\n",
        "    coefficient = np.linalg.solve(np.array([[sum_b2,sum_b],[max_b2,max_b]]),\n",
        "                                             np.array([sum_g,max_g]))\n",
        "    nimg[1] = np.minimum((nimg[1]**2)*coefficient[0] + nimg[1]*coefficient[1],255)\n",
        "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n",
        "\n",
        "def retinex_with_adjust(nimg):\n",
        "    return retinex_adjust(retinex(nimg))\n",
        "\n",
        "def standard_deviation_weighted_grey_world(nimg,subwidth,subheight):\n",
        "    \"\"\"\n",
        "    This function does not work correctly\n",
        "    \"\"\"\n",
        "    nimg = nimg.astype(np.uint32)\n",
        "    height, width,ch = nimg.shape\n",
        "    strides = nimg.itemsize*np.array([width*subheight,subwidth,width,3,1])\n",
        "    shape = (height/subheight, width/subwidth, subheight, subwidth,3)\n",
        "    blocks = np.lib.stride_tricks.as_strided(nimg, shape=shape, strides=strides)\n",
        "    y,x = blocks.shape[:2]\n",
        "    std_r = np.zeros([y,x],dtype=np.float16)\n",
        "    std_g = np.zeros([y,x],dtype=np.float16)\n",
        "    std_b = np.zeros([y,x],dtype=np.float16)\n",
        "    std_r_sum = 0.0\n",
        "    std_g_sum = 0.0\n",
        "    std_b_sum = 0.0\n",
        "    for i in xrange(y):\n",
        "        for j in xrange(x):\n",
        "            subblock = blocks[i,j]\n",
        "            subb = subblock.transpose(2, 0, 1)\n",
        "            std_r[i,j]=np.std(subb[0])\n",
        "            std_g[i,j]=np.std(subb[1])\n",
        "            std_b[i,j]=np.std(subb[2])\n",
        "            std_r_sum += std_r[i,j]\n",
        "            std_g_sum += std_g[i,j]\n",
        "            std_b_sum += std_b[i,j]\n",
        "    sdwa_r = 0.0\n",
        "    sdwa_g = 0.0\n",
        "    sdwa_b = 0.0\n",
        "    for i in xrange(y):\n",
        "        for j in xrange(x):\n",
        "            subblock = blocks[i,j]\n",
        "            subb = subblock.transpose(2, 0, 1)\n",
        "            mean_r=np.mean(subb[0])\n",
        "            mean_g=np.mean(subb[1])\n",
        "            mean_b=np.mean(subb[2])\n",
        "            sdwa_r += (std_r[i,j]/std_r_sum)*mean_r\n",
        "            sdwa_g += (std_g[i,j]/std_g_sum)*mean_g\n",
        "            sdwa_b += (std_b[i,j]/std_b_sum)*mean_b\n",
        "    sdwa_avg = (sdwa_r+sdwa_g+sdwa_b)/3\n",
        "    gain_r = sdwa_avg/sdwa_r\n",
        "    gain_g = sdwa_avg/sdwa_g\n",
        "    gain_b = sdwa_avg/sdwa_b\n",
        "    nimg = nimg.transpose(2, 0, 1)\n",
        "    nimg[0] = np.minimum(nimg[0]*gain_r,255)\n",
        "    nimg[1] = np.minimum(nimg[1]*gain_g,255)\n",
        "    nimg[2] = np.minimum(nimg[2]*gain_b,255)\n",
        "    return nimg.transpose(1, 2, 0).astype(np.uint8)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RMzF8_lQH-Mp",
        "colab": {}
      },
      "source": [
        "# Final Feature Extraction Algo\n",
        "# See if there any room for improvements\n",
        "# See if colour consistency make any changes for real\n",
        "def FeatureExtraction(img):\n",
        "\n",
        "    img = Ying_2017_CAIP(img)\n",
        "    pil_image=to_pil(retinex((img)))\n",
        "    open_cv_image = np.array(pil_image) \n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
        "    edgeEnhanced=edgeEnhancement(hist_equalization_result)\n",
        "    gray= Convert2Grayscale(edgeEnhanced)\n",
        "    return gray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4-vIAo-KH-Ms",
        "colab": {}
      },
      "source": [
        "def FeatureExtractionWithoutGrayScaleConversion(img):\n",
        "    img = Ying_2017_CAIP(img)\n",
        "    pil_image=to_pil(retinex((img)))\n",
        "    open_cv_image = np.array(pil_image) \n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
        "    edgeEnhanced=edgeEnhancement(hist_equalization_result)/255\n",
        "    return edgeEnhanced"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PUz7IkDuH-My",
        "colab": {}
      },
      "source": [
        "def FeatureExtractionHSV(img):\n",
        "    hsvImg = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    return hsvImg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XxPnSiTfH-M4",
        "colab": {}
      },
      "source": [
        "def ProposedSegmentationAlgoWithDisplay(path): \n",
        "    img=loadSampleImg(path)\n",
        "    img = Ying_2017_CAIP(img)\n",
        "    pil_image=to_pil(retinex((img)))\n",
        "    open_cv_image = np.array(pil_image) \n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "    hist_equalization_result = HistogramEqualization(open_cv_image)\n",
        "    edgeEnhanced=edgeEnhancement(hist_equalization_result)\n",
        "    gray= Convert2Grayscale(edgeEnhanced)\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=4)\n",
        "    ax[0].imshow(img)\n",
        "    ax[1].imshow(hist_equalization_result)\n",
        "    ax[2].imshow(edgeEnhanced)\n",
        "    ax[3].imshow(gray)\n",
        "    plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jcG6wHTH-NA",
        "colab": {}
      },
      "source": [
        "def rBrightness(image,ratio):\n",
        "    hsv=cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
        "    brightness=np.float64(hsv[:, :, 2])\n",
        "    brightness=brightness*(1.0+np.random.uniform(-ratio,ratio))\n",
        "    brightness[brightness>255]=255\n",
        "    brightness[brightness<0]=0\n",
        "    hsv[:, :, 2]=brightness\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "def rRotation(image, angle):\n",
        "    if angle==0:\n",
        "        return image\n",
        "    angle=np.random.uniform(-angle,angle)\n",
        "    rows,cols=image.shape[:2]\n",
        "    size=rows,cols\n",
        "    center=rows/2,cols/2\n",
        "    scale=1.0\n",
        "    rotation=cv2.getRotationMatrix2D(center,angle,scale)\n",
        "    return cv2.warpAffine(image,rotation,size)\n",
        "def rTranslation(image, translation):\n",
        "    if translation==0:\n",
        "        return 0\n",
        "    rows,cols=image.shape[:2]\n",
        "    size=rows,cols\n",
        "    x=np.random.uniform(-translation,translation)\n",
        "    y=np.random.uniform(-translation,translation)\n",
        "    trans=np.float32([[1,0,x],[0,1,y]])\n",
        "    return cv2.warpAffine(image,trans,size)\n",
        "def rShear(image, shear):\n",
        "    if shear==0:\n",
        "        return image\n",
        "    rows,cols=image.shape[:2]\n",
        "    size=rows,cols\n",
        "    left,right,top,bottom=shear,cols-shear,shear,rows-shear\n",
        "    dx=np.random.uniform(-shear,shear)\n",
        "    dy=np.random.uniform(-shear,shear)\n",
        "    p1=np.float32([[left,top],[right,top],[left,bottom]])\n",
        "    p2=np.float32([[left+dx,top],[right+dx,top+dy],[left,bottom+dy]])\n",
        "    move=cv2.getAffineTransform(p1,p2)\n",
        "    return cv2.warpAffine(image,move,size)\n",
        "def augment_image(image,brightness,angle,translation,shear):\n",
        "    image=rBrightness(image,brightness)\n",
        "    image=rRotation(image,angle)\n",
        "    image=rTranslation(image,translation)\n",
        "    image=rShear(image,shear)\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdI8-D_KV8TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cv2_clipped_zoom(img, zoom_factor):\n",
        "    \"\"\"\n",
        "    Center zoom in/out of the given image and returning an enlarged/shrinked view of \n",
        "    the image without changing dimensions\n",
        "    Args:\n",
        "        img : Image array\n",
        "        zoom_factor : amount of zoom as a ratio (0 to Inf)\n",
        "    \"\"\"\n",
        "    height, width = img.shape[:2] # It's also the final desired shape\n",
        "    new_height, new_width = int(height * zoom_factor), int(width * zoom_factor)\n",
        "\n",
        "    ### Crop only the part that will remain in the result (more efficient)\n",
        "    # Centered bbox of the final desired size in resized (larger/smaller) image coordinates\n",
        "    y1, x1 = max(0, new_height - height) // 2, max(0, new_width - width) // 2\n",
        "    y2, x2 = y1 + height, x1 + width\n",
        "    bbox = np.array([y1,x1,y2,x2])\n",
        "    # Map back to original image coordinates\n",
        "    bbox = (bbox / zoom_factor).astype(np.int)\n",
        "    y1, x1, y2, x2 = bbox\n",
        "    cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "    # Handle padding when downscaling\n",
        "    resize_height, resize_width = min(new_height, height), min(new_width, width)\n",
        "    pad_height1, pad_width1 = (height - resize_height) // 2, (width - resize_width) //2\n",
        "    pad_height2, pad_width2 = (height - resize_height) - pad_height1, (width - resize_width) - pad_width1\n",
        "    pad_spec = [(pad_height1, pad_height2), (pad_width1, pad_width2)] + [(0,0)] * (img.ndim - 2)\n",
        "\n",
        "    result = cv2.resize(cropped_img, (resize_width, resize_height))\n",
        "    result = np.pad(result, pad_spec, mode='constant')\n",
        "    assert result.shape[0] == height and result.shape[1] == width\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjZjra45V7o-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def another_augment(img):\n",
        "  # image_with_random_noise = random_noise(img)\n",
        "  #play with the contrast\n",
        "  v_min, v_max = np.percentile(img, (0.2, 99.8))\n",
        "  better_contrast = exposure.rescale_intensity(img, in_range=(v_min, v_max))\n",
        "  gamma_img=exposure.adjust_gamma(better_contrast, gamma=0.4, gain=0.9)\n",
        "  horizontal_flip = gamma_img[:, ::-1]\n",
        "  vertical_flip = horizontal_flip[::-1, :]\n",
        "  img_final=cv2_clipped_zoom(vertical_flip,1.5)\n",
        "  return img_final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3zJ6K0dAH-ND",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00000/00000_00024.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00000/00000_00000.ppm')\n",
        "# img=readImage('../DataSet/Training_DataSet/Final_Training/Images/00000/00000_00000.ppm')\n",
        "# print(np.float32(FeatureExtractionWithoutGrayScaleConversion(img)/255))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FwI7Wd32H-NI",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00001/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00001/00001_00008.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00001/00042_00029.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0DrtmDWH-NM",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00002/00002_00002.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00002/00002_00003.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00002/00001_00026.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00002/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00002/00001_00005.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YBDG23AGH-NS",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00004_00022.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00001_00016.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00000_00006.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00002_00002.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00002_00003.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00001_00026.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00003/00001_00005.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VBHACNKRH-NW",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00000_00008.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00002_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00001_00001.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00047_00026.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00005_00029.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00004/00006_00029.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rNSvL1yTH-Na",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00001_00028.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00000_00026.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00007_00010.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00047_00026.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00011_00006.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00005/00010_00026.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0FdLLnmDH-Nf",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00006/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00006/00000_00029.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00006/00003_00025.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tvkM8EgWH-Nj",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00007/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00007/00002_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00007/00000_00028.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00007/00004_00017.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t_jTHxmCH-Nm",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00008/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00008/00000_00029.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00008/00002_00029.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00008/00005_00002.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00008/00007_00026.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DqJgJqupH-Nq",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00009/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00009/00047_00026.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMwinzYDH-Nv",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00010/00007_00024.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00010/00008_00012.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aHJ6lrEjH-Ny",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00011/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00011/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00011/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NUJqQJ-RH-N1",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00012/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00012/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00012/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0D7Tssi1H-N6",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00013/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00013/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00013/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hJWnYYOgH-N-",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00014/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00014/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00014/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "POJYm3uzH-OE",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00015/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00015/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00015/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7sHvwcjkH-OH",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00016/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00016/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00016/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8LGsGAdaH-OK",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00017/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00017/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00017/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bi4yFENZH-OR",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00018/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00018/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00018/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JhFsakkxH-OW",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00019/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00019/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00019/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lvqxNkiAH-Ob",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00020/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00020/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00020/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i9l5JvSIH-Oe",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00021/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00021/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00021/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VNwMhkD3H-Ok",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00022/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00022/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00022/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exaMJfAjH-Or",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00023/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00023/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00023/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7BgrDZzqH-Ou",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00024/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00024/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00024/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wwbeqffuH-Oy",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00025/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00025/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00025/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hUQMTVffH-O2",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00026/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00026/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00026/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e9IdDECOH-O6",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00027/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00027/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00027/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DrsPt3bkH-O_",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00028/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00028/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00028/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zDBnC6EBH-PD",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00029/00004_00028.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00029/00006_00002.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t91Biv0MH-PG",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00030/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00030/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00030/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eh-679PH-PI",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00031/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00031/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00031/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wdbKIXNGH-PK",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00032/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00032/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00032/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GA-iCXeDH-PM",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00033/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00033/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00033/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A1xbQs3cH-PO",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00034/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00034/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00034/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHrLXrLiH-PQ",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00035/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00035/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00035/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gTM1Y56uH-PT",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00036/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00036/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00036/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3b2WX-a_H-PX",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00037/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00037/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00037/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fm1AZvb5H-PZ",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00038/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00038/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00038/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nwirUAWTH-Pd",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00039/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00039/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00039/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XPz1gR0nH-Pn",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00040/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00040/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00040/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dKWkEilFH-Pr",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00041/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00041/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00041/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rnE_gpg3H-Pu",
        "colab": {}
      },
      "source": [
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00042/00000_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00042/00001_00000.ppm')\n",
        "# ProposedSegmentationAlgoWithDisplay('../DataSet/Training_DataSet/Final_Training/Images/00042/00002_00001.ppm')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}